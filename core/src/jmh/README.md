<!--
  Licensed to the Apache Software Foundation (ASF) under one
  or more contributor license agreements.  See the NOTICE file
  distributed with this work for additional information
  regarding copyright ownership.  The ASF licenses this file
  to you under the Apache License, Version 2.0 (the
  "License"); you may not use this file except in compliance
  with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing,
  software distributed under the License is distributed on an
  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
  KIND, either express or implied.  See the License for the
  specific language governing permissions and limitations
  under the License.
-->

# JMH-Based Microbenchmark Suite for Gravitino

## Overview

This directory contains a JMH-based microbenchmark suite tailored for Gravitino. It helps assess the performance characteristics of core subsystems such as the entity cache, metadata resolution logic, and concurrency control mechanisms. The suite can be executed with the following command:

```shell
./gradlew :core:jmh
```
After running the tests, the results will be stored in the `build/reports/jmh` directory. A typical report as generated by JMH will look like this: 

```text
Benchmark                                                   (totalCnt)   Mode  Cnt         Score         Error  Units
EntityCacheClearBenchmark.benchmarkClear                            10  thrpt   10    536704.823 ±   36351.106  ops/s
EntityCacheClearBenchmark.benchmarkClear                           100  thrpt   10     89391.338 ±    4692.738  ops/s
EntityCacheClearBenchmark.benchmarkClear                          1000  thrpt   10      8406.573 ±     738.173  ops/s
EntityCacheContainsBenchmark.benchmarkContains                      10  thrpt   10  19008727.286 ± 1172892.696  ops/s
EntityCacheContainsBenchmark.benchmarkContains                     100  thrpt   10  19129605.626 ±  928728.148  ops/s
EntityCacheContainsBenchmark.benchmarkContains                    1000  thrpt   10  17954917.808 ±  916939.288  ops/s
EntityCacheContainsBenchmark.benchmarkContainsWithRelation          10  thrpt   10   9454829.072 ±  403482.020  ops/s
EntityCacheContainsBenchmark.benchmarkContainsWithRelation         100  thrpt   10   5910924.166 ±  234228.471  ops/s
EntityCacheContainsBenchmark.benchmarkContainsWithRelation        1000  thrpt   10   1021172.939 ±  188152.980  ops/s
EntityCacheGetBenchmark.benchmarkGet                                10  thrpt   10  17646662.661 ± 1850512.796  ops/s
EntityCacheGetBenchmark.benchmarkGet                               100  thrpt   10  17906401.139 ±  905521.957  ops/s
EntityCacheGetBenchmark.benchmarkGet                              1000  thrpt   10  17882451.612 ± 1013749.411  ops/s
EntityCacheGetBenchmark.benchmarkGetWithRelations                   10  thrpt   10   7949607.041 ±  323537.818  ops/s
EntityCacheGetBenchmark.benchmarkGetWithRelations                  100  thrpt   10   4939219.694 ±   54283.320  ops/s
EntityCacheGetBenchmark.benchmarkGetWithRelations                 1000  thrpt   10   1060788.506 ±   22922.363  ops/s
EntityCacheInvalidateBenchmark.benchmarkInvalidate                  10  thrpt   10    184227.751 ±    6303.043  ops/s
EntityCacheInvalidateBenchmark.benchmarkInvalidate                 100  thrpt   10     19663.536 ±     684.142  ops/s
EntityCacheInvalidateBenchmark.benchmarkInvalidate                1000  thrpt   10      1651.429 ±     213.587  ops/s
EntityCachePutBenchmark.benchmarkPut                                10  thrpt   10    222207.294 ±   10992.713  ops/s
EntityCachePutBenchmark.benchmarkPut                               100  thrpt   10     20128.455 ±     434.551  ops/s
EntityCachePutBenchmark.benchmarkPut                              1000  thrpt   10      1902.510 ±      75.715  ops/s
EntityCachePutBenchmark.benchmarkPutWithRelation                    10  thrpt   10    335683.335 ±   34641.231  ops/s
EntityCachePutBenchmark.benchmarkPutWithRelation                   100  thrpt   10     26415.590 ±    1511.666  ops/s
EntityCachePutBenchmark.benchmarkPutWithRelation                  1000  thrpt   10      2345.904 ±      89.693  ops/s
EntityCacheSizeBenchmark.entityCacheSize                            10  thrpt   10   9416189.995 ± 1018247.698  ops/s
EntityCacheSizeBenchmark.entityCacheSize                           100  thrpt   10    944383.407 ±   35235.930  ops/s
EntityCacheSizeBenchmark.entityCacheSize                          1000  thrpt   10     79938.016 ±    2466.431  ops/s
EntityCacheClearBenchmark.benchmarkClear                            10   avgt   10        ≈ 10⁻⁵                 s/op
EntityCacheClearBenchmark.benchmarkClear                           100   avgt   10        ≈ 10⁻⁴                 s/op
EntityCacheClearBenchmark.benchmarkClear                          1000   avgt   10        ≈ 10⁻³                 s/op
EntityCacheContainsBenchmark.benchmarkContains                      10   avgt   10        ≈ 10⁻⁷                 s/op
EntityCacheContainsBenchmark.benchmarkContains                     100   avgt   10        ≈ 10⁻⁷                 s/op
EntityCacheContainsBenchmark.benchmarkContains                    1000   avgt   10        ≈ 10⁻⁷                 s/op
EntityCacheContainsBenchmark.benchmarkContainsWithRelation          10   avgt   10        ≈ 10⁻⁶                 s/op
EntityCacheContainsBenchmark.benchmarkContainsWithRelation         100   avgt   10        ≈ 10⁻⁶                 s/op
EntityCacheContainsBenchmark.benchmarkContainsWithRelation        1000   avgt   10        ≈ 10⁻⁵                 s/op
EntityCacheGetBenchmark.benchmarkGet                                10   avgt   10        ≈ 10⁻⁷                 s/op
EntityCacheGetBenchmark.benchmarkGet                               100   avgt   10        ≈ 10⁻⁷                 s/op
EntityCacheGetBenchmark.benchmarkGet                              1000   avgt   10        ≈ 10⁻⁷                 s/op
EntityCacheGetBenchmark.benchmarkGetWithRelations                   10   avgt   10        ≈ 10⁻⁶                 s/op
EntityCacheGetBenchmark.benchmarkGetWithRelations                  100   avgt   10        ≈ 10⁻⁶                 s/op
EntityCacheGetBenchmark.benchmarkGetWithRelations                 1000   avgt   10        ≈ 10⁻⁵                 s/op
EntityCacheInvalidateBenchmark.benchmarkInvalidate                  10   avgt   10        ≈ 10⁻⁵                 s/op
EntityCacheInvalidateBenchmark.benchmarkInvalidate                 100   avgt   10        ≈ 10⁻⁴                 s/op
EntityCacheInvalidateBenchmark.benchmarkInvalidate                1000   avgt   10         0.002 ±       0.001   s/op
EntityCachePutBenchmark.benchmarkPut                                10   avgt   10        ≈ 10⁻⁵                 s/op
EntityCachePutBenchmark.benchmarkPut                               100   avgt   10        ≈ 10⁻⁴                 s/op
EntityCachePutBenchmark.benchmarkPut                              1000   avgt   10         0.002 ±       0.001   s/op
EntityCachePutBenchmark.benchmarkPutWithRelation                    10   avgt   10        ≈ 10⁻⁵                 s/op
EntityCachePutBenchmark.benchmarkPutWithRelation                   100   avgt   10        ≈ 10⁻⁴                 s/op
EntityCachePutBenchmark.benchmarkPutWithRelation                  1000   avgt   10         0.002 ±       0.001   s/op
EntityCacheSizeBenchmark.entityCacheSize                            10   avgt   10        ≈ 10⁻⁶                 s/op
EntityCacheSizeBenchmark.entityCacheSize                           100   avgt   10        ≈ 10⁻⁵                 s/op
EntityCacheSizeBenchmark.entityCacheSize                          1000   avgt   10        ≈ 10⁻⁴                 s/op
```
`Error` Indicates the confidence interval margin (i.e., the range of deviation) for the Score, usually computed at a 99.9% confidence level, representing the standard error. This means the actual performance is expected to lie within the range of Score ± Error in most cases.

```text
Score: 19008727.28 ops/s  
Error: ± 1172892.70 ops/s  
→ Actual performance is likely between 17,835,834 and 20,181,620 ops/s
```

This shows the variability of the benchmark result — the smaller the Error (both in absolute and relative terms), the more stable and reliable the measurement.

## JMH

JMH (Java Microbenchmark Harness) is a benchmarking framework developed by the OpenJDK team for building, running, and analyzing precise Java microbenchmarks. It is specifically designed to measure the performance of fine-grained operations, such as method calls, cache access, or object allocations, where millisecond-level accuracy is not sufficient.

Unlike traditional benchmarking approaches, JMH takes into account critical factors such as:

- JVM warm-up (JIT compilation effects)
- Dead-code elimination 
- Escape analysis 
- Thread contention and false sharing

JMH provides a reliable, annotation-driven API for defining benchmarks and automatically handles warm-up iterations, multiple forks, and statistical result reporting. It is widely used in performance-sensitive Java projects such as JDK, Spring, Netty, Apache Lucene, and many others.

A typical Example benchmark in JMH:

```java
@BenchmarkMode({Mode.Throughput, Mode.AverageTime})
@OutputTimeUnit(TimeUnit.SECONDS)
@State(Scope.Thread)
public class StringConnectTest {

  @Param(value = {"10", "50", "100"})
  private int length;

  @Benchmark
  public void testStringAdd(Blackhole blackhole) {
    String a = "";
    for (int i = 0; i < length; i++) {
      a += i;
    }
    blackhole.consume(a);
  }

  @Benchmark
  public void testStringBuilderAdd(Blackhole blackhole) {
    StringBuilder sb = new StringBuilder();
    for (int i = 0; i < length; i++) {
      sb.append(i);
    }
    blackhole.consume(sb.toString());
  }

  public static void main(String[] args) throws RunnerException {
    Options opt = new OptionsBuilder()
        .include(StringConnectTest.class.getSimpleName())
        .result("result.json")
        .resultFormat(ResultFormatType.JSON).build();
    new Runner(opt).run();
  }
}
```
- `@Benchmark`: Declares the method as a benchmark. JMH will repeatedly invoke and measure this method during the benchmark run. 
- `@BenchmarkMode()`: Specifies the benchmarking modes JMH should use for all methods in the class.
- `@OutputTimeUnit()`: Sets the time unit used in benchmark results. In this case, results will be displayed in Seconds.
- `@State()`: Specifies the scope of the benchmark. In this case, the state is shared across all threads.
    - `Scope.Thread`: A separate instance of the benchmark class will be created for each thread 
      running the benchmark. This ensures thread-local isolation (no shared state), which is ideal for measuring single-threaded performance or avoiding data races.
    - `Scope.Benchmark`: shared across all threads (for shared-state benchmarks).
    - `Scope.Group`: shared within a thread group (used in group benchmarks)
- `@Param(value = {"10", "50", "100"})`: The `@Param` annotation is used in JMH to parameterize benchmarks. It allows you to run the same benchmark multiple times with different input values, helping you analyze performance under various configurations.

For `@BenchmarkMode()`, the following modes are available:

| Mode                  | Meaning                                                                   |
|-----------------------|---------------------------------------------------------------------------|
| `Mode.Throughput`     | Measures how many operations are completed per second or millisecond.     |
| `Mode.AverageTime`    | Measures the average execution time per operation.                        |
| `Mode.SampleTime`     | Samples the execution time over multiple iterations to show distribution. |
| `Mode.SingleShotTime` | Measures the time for a single invocation (used for cold start analysis). |
| `Mode.All`            | Runs all available modes and reports results for each.                    |


## Running the Tests

In Gravitino, we use the [jmh-gradle-plugin](https://github.com/melix/jmh-gradle-plugin) to 
integrate JMH testing into the Gradle build system.

This plugin simplifies running JMH tests by:

- Automatically generating the test harness.
- Providing built-in Gradle tasks (e.g., `:core:jmh`).

To run the JMH tests in Gravitino, use the following Gradle command:

```bash
./gradlew :core:jmh 
```

## jmh-gradle-plugin

We can configure the JMH tests by adding the following configuration to the `build.gradle` file:

```gradle
plugins {
  id "me.champeau.jmh" version "0.7.3"
}
```

> Note: Versions of the plugin prior to 0.6.0 used the `me.champeau.gradle.jmh` plugin id.

The Integration Samples as follows:

- [Built-in samples](https://github.com/melix/jmh-gradle-plugin/tree/master/samples) 
- [java@8 + gradle@7.1](https://github.com/twoVersatile/jmhsample)

### What plugin version to use?

| Gradle | Minimal plugin version                 |
|--------|----------------------------------------|
| 8.0    | 0.7.0                                  |
| 7.0    | 0.5.3                                  |
| 5.5    | 0.5.0                                  |
| 5.1    | 0.4.8                                  |
| 4.9    | 0.4.7 (to benefit from lazy tasks API) |
| 4.8    | 0.4.5                                  |
| 4.7    | 0.4.5                                  |
| 4.6    | 0.4.5                                  |
| 4.5    | 0.4.5                                  |
| 4.4    | 0.4.5                                  |
| 4.3    | 0.4.5                                  |
| 4.2    | 0.4.4                                  |
| 4.1    | 0.4.4                                  |

### Usage

The plugin makes it easy to integrate into an existing project thanks to a specific configuration. In particular, benchmark source files are expected to be found in the `src/jmh` directory:

```text
src/jmh
     |- java       : java sources for benchmarks
     |- resources  : resources for benchmarks
```

The plugin creates a jmh configuration that you should use if your benchmark files depend on a 
3rd party library. For example, if you want to use commons-io, you can add the dependency into 
`build.gradle` like this:

```text
dependencies {
    jmh 'commons-io:commons-io:2.7'
}
```

The plugin uses JMH 1.37. You can upgrade the version just by changing the version in the dependencies block:

```text
dependencies {
    jmh 'org.openjdk.jmh:jmh-core:0.9'
    jmh 'org.openjdk.jmh:jmh-generator-annprocess:0.9'
    jmh 'org.openjdk.jmh:jmh-generator-bytecode:0.9'
}
```
### Tasks

The project will add several tasks:

- `jmhClasses`: compiles raw benchmark code 
- `jmhRunBytecodeGenerator`: runs bytecode generator over raw benchmark code and generates actual benchmarks 
- `jmhCompileGeneratedClasses`: compiles generated benchmarks 
- `jmhJar` : builds the JMH jar containing the JMH runtime and your compiled benchmark classes 
- `jmh` : executes the benchmarks

The jmh task is the main task and depends on the others so it is in general sufficient to execute this task:

```shell
./gradlew :core:jmh
```

### Configuration options

By default, all benchmarks will be executed, and the results will be generated into `$buildDir/reports/jmh`. But you can change various options thanks to the jmh configuration block. All configurations variables apart from includes are unset, implying that they fall back to the default JMH values:

```gradle
jmh {
   includes = ['some regular expression'] // include pattern (regular expression) for benchmarks to be executed
   excludes = ['some regular expression'] // exclude pattern (regular expression) for benchmarks to be executed
   iterations = 10 // Number of measurement iterations to do.
   benchmarkMode = ['thrpt','ss'] // Benchmark mode. Available modes are: [Throughput/thrpt, AverageTime/avgt, SampleTime/sample, SingleShotTime/ss, All/all]
   batchSize = 1 // Batch size: number of benchmark method calls per operation. (some benchmark modes can ignore this setting)
   fork = 2 // How many times to forks a single benchmark. Use 0 to disable forking altogether
   failOnError = false // Should JMH fail immediately if any benchmark had experienced the unrecoverable error?
   forceGC = false // Should JMH force GC between iterations?
   jvm = 'myjvm' // Custom JVM to use when forking.
   jvmArgs = ['Custom JVM args to use when forking.']
   jvmArgsAppend = ['Custom JVM args to use when forking (append these)']
   jvmArgsPrepend =[ 'Custom JVM args to use when forking (prepend these)']
   humanOutputFile = project.file("${project.buildDir}/reports/jmh/human.txt") // human-readable output file
   resultsFile = project.file("${project.buildDir}/reports/jmh/results.txt") // results file
   operationsPerInvocation = 10 // Operations per invocation.
   benchmarkParameters =  [:] // Benchmark parameters.
   profilers = [] // Use profilers to collect additional data. Supported profilers: [cl, comp, gc, stack, perf, perfnorm, perfasm, xperf, xperfasm, hs_cl, hs_comp, hs_gc, hs_rt, hs_thr, async]
   timeOnIteration = '1s' // Time to spend at each measurement iteration.
   resultFormat = 'CSV' // Result format type (one of CSV, JSON, NONE, SCSV, TEXT)
   synchronizeIterations = false // Synchronize iterations?
   threads = 4 // Number of worker threads to run with.
   threadGroups = [2,3,4] //Override thread group distribution for asymmetric benchmarks.
   jmhTimeout = '1s' // Timeout for benchmark iteration.
   timeUnit = 'ms' // Output time unit. Available time units are: [m, s, ms, us, ns].
   verbosity = 'NORMAL' // Verbosity mode. Available modes are: [SILENT, NORMAL, EXTRA]
   warmup = '1s' // Time to spend at each warmup iteration.
   warmupBatchSize = 10 // Warmup batch size: number of benchmark method calls per operation.
   warmupForks = 0 // How many warmup forks to make for a single benchmark. 0 to disable warmup forks.
   warmupIterations = 1 // Number of warmup iterations to do.
   warmupMode = 'INDI' // Warmup mode for warming up selected benchmarks. Warmup modes are: [INDI, BULK, BULK_INDI].
   warmupBenchmarks = ['.*Warmup'] // Warmup benchmarks to include in the run in addition to already selected. JMH will not measure these benchmarks, but only use them for the warmup.

   zip64 = true // Use ZIP64 format for bigger archives
   jmhVersion = '1.37' // Specifies JMH version
   includeTests = true // Allows to include test sources into generate JMH jar, i.e. use it when benchmarks depend on the test classes.
   duplicateClassesStrategy = DuplicatesStrategy.FAIL // Strategy to apply when encountring duplicate classes during creation of the fat jar (i.e. while executing jmhJar task)
}
```

The following table describes the mappings between JMH’s command line options and the plugin’s extension properties.

| JMH Option                 | Extension Property      |
|----------------------------|-------------------------|
| `-bm <mode>`               | benchmarkMode           |
| `-bs <int>`                | batchSize               |
| `-e <regexp+>`             | exclude                 |
| `-f <int>`                 | fork                    |
| `-foe <bool>`              | failOnError             |
| `-gc <bool>`               | forceGC                 |
| `-i <int>`                 | iterations              |
| `-jvm <string>`            | jvm                     |
| `-jvmArgs <string>`        | jvmArgs                 |
| `-jvmArgsAppend <string>`  | jvmArgsAppend           |
| `-jvmArgsPrepend <string>` | jvmArgsPrepend          |
| `-o <filename>`            | humanOutputFile         |
| `-opi <int>`               | operationsPerInvocation |
| `-p <param={v,}*>`         | benchmarkParameters?    |
| `-prof <profiler>`         | profilers               |
| `-r <time>`                | timeOnIteration         |
| `-rf <type>`               | resultFormat            |
| `-rff <filename>`          | resultsFile             |
| `-si <bool>`               | synchronizeIterations   |
| `-t <int>`                 | threads                 |
| `-tg <int+>`               | threadGroups            |
| `-to <time>`               | jmhTimeout              |
| `-tu <TU>`                 | timeUnit                |
| `-v <mode>`                | verbosity               |
| `-w <time>`                | warmup                  |
| `-wbs <int>`               | warmupBatchSize         |
| `-wf <int>`                | warmupForks             |
| `-wi <int>`                | warmupIterations        |
| `-wm <mode>`               | warmupMode              |
| `-wmb <regexp+>`           | warmupBenchmarks        |

Currently, the default configuration of the `jmh` plugin is:

```gradle
jmh {
  jmhVersion = "1.37"
  warmupIterations = 5
  iterations = 10
  fork = 1
  threads = 4
  resultFormat = "csv"
  resultsFile = file("$buildDir/reports/jmh/results.csv")
}
```

The `jmh` plugin makes it easy to test existing sources without having to create a separate project for this. This is the reason why you must put your benchmark source files into `src/jmh/java` instead of `src/main/java`. This means that by default, the `jmh` (benchmarks) task depends on your `main` (production) source set.

It is possible a dependency on the test source set by setting property `includeTests` to true inside `jmh` block. 

### Using JMH gradle plugin with shadow plugin

Optionally it is possible to use the [Shadow](https://github.com/GradleUp/shadow) Plugin to do actual JMH jar creation. The configuration of Shadow Plugin for JMH jar is done via jmhJar block.

For example:

```gradle
jmhJar {
  append('META-INF/spring.handlers')
  append('META-INF/spring.schemas')
  exclude 'LICENSE'
}
```

### Duplicate dependencies and classes

This plugin will merge all dependencies that are defined as part of jmh, runtime and optionally testRuntime configurations into a single set from which fat jar will be created when executing jmhJar task. This is done to ensure that no duplicate dependencies will be added the generated jar.

In addition plugin applies [DuplicatesStrategy](https://docs.gradle.org/current/javadoc/org/gradle/api/file/DuplicatesStrategy.html) defined via `duplicateClassesStrategy` extension property to every class while creating fat jar. By default this property is set to `DuplicatesStrategy.FAIL` which means that upon detection of duplicate classes the task will fail.

It is possible to change this behavior by configuring duplicateClassesStrategy property via `jmh` block, e.g.:

```gradle
jmh {
  duplicateClassesStrategy = DuplicatesStrategy.WARN
}
```

If you do encounter problem with defaut value it means that the classpath or sources in your project do contain duplicate classes which means that it is not possible to predict which one will be used when fat jar will generated.

## Other information about JMH

### Why Warm-up Is Needed in JMH

Due to the JVM's Just-In-Time (JIT) compilation mechanism, methods that are invoked frequently may be compiled into native machine code to improve execution speed. Therefore, to ensure that benchmark results reflect the real-world performance more accurately, a warm-up phase is necessary before actual measurement begins.

### JMH Visualization

In addition, if you want to visualize your benchmark results as charts, you can try the following tools:

- JMH Visual Chart: http://deepoove.com/jmh-visual-chart/
- JMH Visualizer: https://jmh.morethan.io/

For example, you can import the JSON output from the benchmark example above into one of these tools to generate interactive visualizations.

### Running JMH Benchmarks via IntelliJ Plugin

You can also make JMH benchmarking easier by installing the JMH Plugin in IntelliJ IDEA. To do this, go to `File → Settings... → Plugins`, search for "JMH", and install the JMH plugin. This plugin allows you to work with JMH just like you would with JUnit. Its main features include:

- Automatically generating methods annotated with `@Benchmark`
- Running individual benchmark methods (like running a JUnit test)
- Running all `@Benchmark` methods in a class

For example, Right-click and select `Generate... → Generate JMH benchmark` to insert a method stub with `@Benchmark`. Move the cursor to a method signature and choose Run to execute just that benchmark. Move the cursor to the class name line and right-click Run to execute all benchmark methods in that class.